{"cells":[{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":6161,"status":"ok","timestamp":1680367338192,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"Yi5efqJnAsI6"},"outputs":[],"source":["import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.stem import PorterStemmer # Returns word to its origin\n","import numpy as np # For scientific computing and data analysis\n","import tensorflow as tf\n","from tensorflow import keras\n","import json\n","from tensorflow.keras.callbacks import TensorBoard"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":467,"status":"ok","timestamp":1680367338655,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"XDCxokkyAsGN","outputId":"6f93186d-92a3-401e-f2b1-74a29e6b63e1"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\ahmed_2tllwxa\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\ahmed_2tllwxa\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["nltk.download('punkt')\n","nltk.download('wordnet')"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":1194,"status":"ok","timestamp":1680367366156,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"w308MzBHAsDv"},"outputs":[],"source":["# load the intents dataset\n","with open('data.json', \"rb\") as file:\n","  #/content/drive/MyDrive/Colab Notebooks/ChatbotDataset.json\n","    intents = json.load(file)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1680367366157,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"2CtvSigJAwkA"},"outputs":[],"source":["# create lemmatizer object\n","lemmatizer = WordNetLemmatizer()\n","# WordNetLemmatizer is a tool used in natural language processing to convert words to their base or root form"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1680367366158,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"XaAXvOBudAyD"},"outputs":[],"source":["# Difference between PorterStemmer and WordNetLemmatizer:\n","# PorterStemmer is a rule-based algorithm that removes the suffixes from words to generate the root form.\n","# WordNetLemmatizer uses a dictionary-based approach and takes into account the context and part of speech \n","# of the word to generate the base form."]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1680367366158,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"Ly-Brz7sAwfD"},"outputs":[],"source":["# create empty lists to hold the tokenized words, classes, and documents\n","words = []\n","classes = []\n","documents = []\n","ignore_words = ['?', '!']"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1680367366159,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"ede-djPIAwcu"},"outputs":[],"source":["# loop through each sentence in the intents patterns and tokenize the words\n","for intent in intents['intents']:\n","    for pattern in intent['patterns']:\n","        # tokenize each word in the sentence\n","        w = nltk.word_tokenize(pattern)\n","        # add the tokenized words to the words list\n","        words.extend(w)\n","        # add the tokenized words and class to the documents list\n","        documents.append((w, intent['tag']))\n","        # add the class to the classes list\n","        if intent['tag'] not in classes:\n","            classes.append(intent['tag'])"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":1986,"status":"ok","timestamp":1680367368138,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"UNYSIeAEAsCG"},"outputs":[],"source":["# lemmatize the words and remove duplicates\n","words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n","words = sorted(list(set(words)))\n"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1680367368139,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"KGIWsCJrAr_5"},"outputs":[],"source":["# sort the classes\n","classes = sorted(list(set(classes)))"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1680367368141,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"gnM5uR7dAr8o"},"outputs":[{"ename":"AttributeError","evalue":"'numpy.ndarray' object has no attribute 'append'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[36], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m output_row[classes\u001b[39m.\u001b[39mindex(doc[\u001b[39m1\u001b[39m])] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[39m# add the training data to the final list\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m training\u001b[39m.\u001b[39;49mappend([bag, output_row])\n","\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"]}],"source":["# create the training data\n","training = []\n","output_empty = [0] * len(classes)\n","\n","for doc in documents:\n","    # initialize the bag of words for each document\n","    bag = []\n","    # tokenize each word in the document and lemmatize it\n","    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in doc[0]]\n","    # create the bag of words for this document\n","    for w in words:\n","        bag.append(1) if w in pattern_words else bag.append(0)\n","\n","    # create the output row\n","    output_row = list(output_empty)\n","    output_row[classes.index(doc[1])] = 1\n","\n","    # add the training data to the final list\n","    training.append([bag, output_row])\n","    "]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["# create the training data\n","train_x = []\n","train_y = []\n","\n","for doc in documents:\n","    # initialize the bag of words for each document\n","    bag = []\n","    # tokenize each word in the document and lemmatize it\n","    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in doc[0]]\n","    # create the bag of words for this document\n","    for w in words:\n","        bag.append(1) if w in pattern_words else bag.append(0)\n","\n","    # create the output row\n","    output_row = list(output_empty)\n","    output_row[classes.index(doc[1])] = 1\n","\n","    # add the bag-of-words representation and output row to their respective lists\n","    train_x.append(bag)\n","    train_y.append(output_row)\n","\n","# convert the lists to numpy arrays\n","train_x = np.array(train_x)\n","train_y = np.array(train_y)\n","\n","# shuffle the training data\n","indices = np.arange(train_x.shape[0])\n","np.random.shuffle(indices)\n","train_x = train_x[indices]\n","train_y = train_y[indices]\n","\n","# Rest of the code...\n"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[]\n"]}],"source":["# len(training)\n","print(training)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1680367368141,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"npzRzriBA-zs","outputId":"c57e023b-7c38-45fb-c49b-be74469b84b7"},"outputs":[{"ename":"ValueError","evalue":"setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (109, 2) + inhomogeneous part.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[29], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# shuffle the training data and convert it to a numpy array\u001b[39;00m\n\u001b[0;32m      2\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mshuffle(training)\n\u001b[1;32m----> 3\u001b[0m training \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(training)\n","\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (109, 2) + inhomogeneous part."]}],"source":["# shuffle the training data and convert it to a numpy array\n","np.random.shuffle(training)\n","training = np.array(training)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1680367368142,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"A9mzZBbPA-yH"},"outputs":[],"source":["# split the training data into input and output sets\n","train_x = list(training[:, 0])\n","train_y = list(training[:, 1])"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1680367368142,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"JE9H2uUfA-vH"},"outputs":[],"source":["# define the model architecture\n","model = keras.Sequential([\n","    keras.layers.Dense(128, input_shape=(len(train_x[0]),), activation='relu'),\n","    keras.layers.Dropout(0.5),\n","    keras.layers.Dense(64, activation='relu'),\n","    keras.layers.Dropout(0.5),\n","    keras.layers.Dense(len(train_y[0]), activation='softmax')\n","])"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1680367368143,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"WrPVwTeJBF94"},"outputs":[],"source":["# compile the model\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["log_dir = \"../Run/FeedForward\"\n","tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":82992,"status":"ok","timestamp":1680367451121,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"ZSBOArf8BF7d","outputId":"7cc53410-11de-4332-ea19-556a5ae23e57"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","2/2 [==============================] - 1s 663ms/step - loss: 0.0348 - accuracy: 0.9817 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 2/100\n","2/2 [==============================] - 0s 389ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 3/100\n","2/2 [==============================] - 0s 389ms/step - loss: 0.0305 - accuracy: 0.9908 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 4/100\n","2/2 [==============================] - 0s 353ms/step - loss: 0.0290 - accuracy: 0.9908 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 5/100\n","2/2 [==============================] - 0s 290ms/step - loss: 0.0359 - accuracy: 0.9817 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 6/100\n","2/2 [==============================] - 0s 317ms/step - loss: 0.0828 - accuracy: 0.9633 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 7/100\n","2/2 [==============================] - 0s 334ms/step - loss: 0.0290 - accuracy: 0.9817 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 8/100\n","2/2 [==============================] - 0s 320ms/step - loss: 0.0289 - accuracy: 0.9908 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 9/100\n","2/2 [==============================] - 0s 362ms/step - loss: 0.0390 - accuracy: 0.9817 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 10/100\n","2/2 [==============================] - 0s 320ms/step - loss: 0.0248 - accuracy: 0.9908 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 11/100\n","2/2 [==============================] - 0s 297ms/step - loss: 0.0420 - accuracy: 0.9725 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 12/100\n","2/2 [==============================] - 0s 287ms/step - loss: 0.0330 - accuracy: 0.9817 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 13/100\n","2/2 [==============================] - 0s 297ms/step - loss: 0.0291 - accuracy: 0.9817 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 14/100\n","2/2 [==============================] - 0s 280ms/step - loss: 0.0265 - accuracy: 0.9817 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 15/100\n","2/2 [==============================] - 0s 297ms/step - loss: 0.0279 - accuracy: 0.9817 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 16/100\n","2/2 [==============================] - 0s 355ms/step - loss: 0.0229 - accuracy: 0.9817 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 17/100\n","2/2 [==============================] - 0s 371ms/step - loss: 0.0454 - accuracy: 0.9725 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 18/100\n","2/2 [==============================] - 0s 307ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 19/100\n","2/2 [==============================] - 0s 236ms/step - loss: 0.0349 - accuracy: 0.9817 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 20/100\n","2/2 [==============================] - 0s 267ms/step - loss: 0.0369 - accuracy: 0.9725 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 21/100\n","2/2 [==============================] - 0s 243ms/step - loss: 0.0261 - accuracy: 0.9817 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 22/100\n","2/2 [==============================] - 0s 250ms/step - loss: 0.0218 - accuracy: 0.9908 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 23/100\n","2/2 [==============================] - 0s 243ms/step - loss: 0.0380 - accuracy: 0.9817 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 24/100\n","2/2 [==============================] - 0s 255ms/step - loss: 0.0335 - accuracy: 0.9817 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 25/100\n","2/2 [==============================] - 0s 451ms/step - loss: 0.0310 - accuracy: 0.9725 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 26/100\n","2/2 [==============================] - 0s 284ms/step - loss: 0.0280 - accuracy: 0.9817 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 27/100\n","2/2 [==============================] - 0s 285ms/step - loss: 0.0297 - accuracy: 0.9817 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 28/100\n","2/2 [==============================] - 0s 361ms/step - loss: 0.0599 - accuracy: 0.9725 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 29/100\n","2/2 [==============================] - 0s 219ms/step - loss: 0.0384 - accuracy: 0.9725 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 30/100\n","2/2 [==============================] - 0s 216ms/step - loss: 0.0333 - accuracy: 0.9908 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 31/100\n","2/2 [==============================] - 0s 220ms/step - loss: 0.0351 - accuracy: 0.9725 - val_loss: 0.0256 - val_accuracy: 0.9817\n","Epoch 32/100\n","2/2 [==============================] - 0s 259ms/step - loss: 0.0369 - accuracy: 0.9633 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 33/100\n","2/2 [==============================] - 0s 212ms/step - loss: 0.0375 - accuracy: 0.9633 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 34/100\n","2/2 [==============================] - 0s 217ms/step - loss: 0.0369 - accuracy: 0.9817 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 35/100\n","2/2 [==============================] - 0s 211ms/step - loss: 0.0605 - accuracy: 0.9633 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 36/100\n","2/2 [==============================] - 0s 214ms/step - loss: 0.0287 - accuracy: 0.9908 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 37/100\n","2/2 [==============================] - 0s 251ms/step - loss: 0.0412 - accuracy: 0.9633 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 38/100\n","2/2 [==============================] - 0s 226ms/step - loss: 0.0303 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 39/100\n","2/2 [==============================] - 0s 236ms/step - loss: 0.0323 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 40/100\n","2/2 [==============================] - 0s 296ms/step - loss: 0.0284 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 41/100\n","2/2 [==============================] - 0s 201ms/step - loss: 0.0455 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 42/100\n","2/2 [==============================] - 0s 245ms/step - loss: 0.0292 - accuracy: 0.9817 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 43/100\n","2/2 [==============================] - 0s 256ms/step - loss: 0.0348 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 44/100\n","2/2 [==============================] - 0s 243ms/step - loss: 0.0293 - accuracy: 0.9817 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 45/100\n","2/2 [==============================] - 0s 221ms/step - loss: 0.0316 - accuracy: 0.9817 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 46/100\n","2/2 [==============================] - 0s 264ms/step - loss: 0.0231 - accuracy: 0.9908 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 47/100\n","2/2 [==============================] - 0s 237ms/step - loss: 0.0333 - accuracy: 0.9908 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 48/100\n","2/2 [==============================] - 0s 205ms/step - loss: 0.0202 - accuracy: 0.9908 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 49/100\n","2/2 [==============================] - 0s 205ms/step - loss: 0.0392 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 50/100\n","2/2 [==============================] - 0s 230ms/step - loss: 0.0287 - accuracy: 0.9817 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 51/100\n","2/2 [==============================] - 0s 229ms/step - loss: 0.0514 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 52/100\n","2/2 [==============================] - 0s 219ms/step - loss: 0.0875 - accuracy: 0.9450 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 53/100\n","2/2 [==============================] - 0s 218ms/step - loss: 0.0270 - accuracy: 0.9908 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 54/100\n","2/2 [==============================] - 0s 224ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 55/100\n","2/2 [==============================] - 0s 221ms/step - loss: 0.0479 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 56/100\n","2/2 [==============================] - 0s 221ms/step - loss: 0.0243 - accuracy: 0.9908 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 57/100\n","2/2 [==============================] - 0s 200ms/step - loss: 0.0325 - accuracy: 0.9817 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 58/100\n","2/2 [==============================] - 0s 197ms/step - loss: 0.0318 - accuracy: 0.9817 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 59/100\n","2/2 [==============================] - 0s 210ms/step - loss: 0.0472 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 60/100\n","2/2 [==============================] - 0s 220ms/step - loss: 0.0476 - accuracy: 0.9541 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 61/100\n","2/2 [==============================] - 0s 205ms/step - loss: 0.0531 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 62/100\n","2/2 [==============================] - 0s 224ms/step - loss: 0.0448 - accuracy: 0.9633 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 63/100\n","2/2 [==============================] - 0s 259ms/step - loss: 0.0278 - accuracy: 0.9908 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 64/100\n","2/2 [==============================] - 0s 298ms/step - loss: 0.0481 - accuracy: 0.9633 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 65/100\n","2/2 [==============================] - 0s 476ms/step - loss: 0.0863 - accuracy: 0.9541 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 66/100\n","2/2 [==============================] - 0s 299ms/step - loss: 0.0232 - accuracy: 0.9908 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 67/100\n","2/2 [==============================] - 0s 261ms/step - loss: 0.0492 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 68/100\n","2/2 [==============================] - 0s 249ms/step - loss: 0.0262 - accuracy: 0.9908 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 69/100\n","2/2 [==============================] - 0s 200ms/step - loss: 0.0267 - accuracy: 0.9908 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 70/100\n","2/2 [==============================] - 0s 301ms/step - loss: 0.0220 - accuracy: 0.9908 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 71/100\n","2/2 [==============================] - 0s 259ms/step - loss: 0.0425 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 72/100\n","2/2 [==============================] - 0s 262ms/step - loss: 0.0309 - accuracy: 0.9908 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 73/100\n","2/2 [==============================] - 0s 241ms/step - loss: 0.0333 - accuracy: 0.9817 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 74/100\n","2/2 [==============================] - 0s 250ms/step - loss: 0.0311 - accuracy: 0.9817 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 75/100\n","2/2 [==============================] - 0s 237ms/step - loss: 0.0381 - accuracy: 0.9817 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 76/100\n","2/2 [==============================] - 0s 226ms/step - loss: 0.0382 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 77/100\n","2/2 [==============================] - 0s 268ms/step - loss: 0.0410 - accuracy: 0.9817 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 78/100\n","2/2 [==============================] - 0s 227ms/step - loss: 0.0470 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 79/100\n","2/2 [==============================] - 0s 248ms/step - loss: 0.0386 - accuracy: 0.9633 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 80/100\n","2/2 [==============================] - 0s 237ms/step - loss: 0.0533 - accuracy: 0.9817 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 81/100\n","2/2 [==============================] - 0s 234ms/step - loss: 0.0341 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 82/100\n","2/2 [==============================] - 0s 239ms/step - loss: 0.0330 - accuracy: 0.9633 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 83/100\n","2/2 [==============================] - 0s 236ms/step - loss: 0.0271 - accuracy: 0.9817 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 84/100\n","2/2 [==============================] - 0s 238ms/step - loss: 0.0232 - accuracy: 0.9908 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 85/100\n","2/2 [==============================] - 0s 267ms/step - loss: 0.0226 - accuracy: 0.9908 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 86/100\n","2/2 [==============================] - 0s 240ms/step - loss: 0.0502 - accuracy: 0.9817 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 87/100\n","2/2 [==============================] - 0s 240ms/step - loss: 0.0282 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 88/100\n","2/2 [==============================] - 0s 249ms/step - loss: 0.0263 - accuracy: 0.9908 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 89/100\n","2/2 [==============================] - 0s 237ms/step - loss: 0.0401 - accuracy: 0.9633 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 90/100\n","2/2 [==============================] - 0s 221ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 91/100\n","2/2 [==============================] - 0s 239ms/step - loss: 0.0295 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 92/100\n","2/2 [==============================] - 0s 248ms/step - loss: 0.0244 - accuracy: 0.9908 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 93/100\n","2/2 [==============================] - 0s 260ms/step - loss: 0.0333 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 94/100\n","2/2 [==============================] - 0s 246ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 95/100\n","2/2 [==============================] - 0s 304ms/step - loss: 0.0237 - accuracy: 0.9908 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 96/100\n","2/2 [==============================] - 0s 245ms/step - loss: 0.0275 - accuracy: 0.9908 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 97/100\n","2/2 [==============================] - 0s 245ms/step - loss: 0.0262 - accuracy: 0.9817 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 98/100\n","2/2 [==============================] - 0s 242ms/step - loss: 0.0419 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 99/100\n","2/2 [==============================] - 0s 237ms/step - loss: 0.0316 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n","Epoch 100/100\n","2/2 [==============================] - 0s 238ms/step - loss: 0.0476 - accuracy: 0.9725 - val_loss: 0.0255 - val_accuracy: 0.9817\n"]}],"source":["# train the model for 100 epochs\n","# model.fit(np.array(train_x), np.array(train_y), epochs=140, batch_size=5, callbacks=[tensorboard_callback])\n","history = model.fit(np.array(train_x), np.array(train_y),validation_data=([np.array(train_x) , np.array(train_y)]), batch_size=64, epochs=100, callbacks=[tensorboard_callback]) "]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":46,"status":"ok","timestamp":1680367451121,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"qzcgemm0D-xe"},"outputs":[],"source":["4# Define function to predict intent\n","def predict_intent(sentence):\n","    sentence_words = nltk.word_tokenize(sentence.lower())\n","    sentence_words = [lemmatizer.lemmatize(word) for word in sentence_words]\n","    bag = [0] * len(words)\n","    for word in sentence_words:\n","        for i, w in enumerate(words):\n","            if w == word:\n","                bag[i] = 1\n","    res = model.predict(np.array([bag]))[0]\n","    ERROR_THRESHOLD = 0.25\n","    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n","    results.sort(key=lambda x: x[1], reverse=True)\n","    return_list = []\n","    for result in results:\n","        return_list.append((classes[result[0]], result[1]))\n","    return return_list"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1680367451122,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"FZkDvEpZCtaZ","outputId":"1d4ca860-4120-4086-d956-23824332b403"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 95ms/step\n","[('greeting', 0.9999962)]\n","1/1 [==============================] - 0s 26ms/step\n","[('weather', 0.99999976)]\n","1/1 [==============================] - 0s 29ms/step\n","[('thankyou', 1.0)]\n","1/1 [==============================] - 0s 26ms/step\n","[('places_to_visit', 1.0)]\n"]}],"source":["# Test model\n","print(predict_intent(\"Hi, how are you?\"))\n","print(predict_intent(\"What's on the menu today?\"))\n","print(predict_intent(\"Thanks\"))\n","print(predict_intent(\"What are some popular places to visit in Egypt?\"))"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":925,"status":"ok","timestamp":1680367452039,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"nVh7565zBF4S"},"outputs":[],"source":["# save the model\n","# model.save('/content/drive/MyDrive/Colab Notebooks/chatbot_model.h5')\n","model.save('/content/chatbot_model.h5')"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1680367452040,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"j4PGzueOBFyY"},"outputs":[],"source":["# load the model\n","# model = keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/chatbot_model.h5')\n","model = keras.models.load_model('/content/chatbot_model.h5')"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1680367452040,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"pmAQKQZRBNwD"},"outputs":[],"source":["# define a function to process user input and get the chatbot response\n","def chatbot_response(text):\n","    # tokenize the user input\n","    input_data = nltk.word_tokenize(text)\n","    # lemmatize the input words and remove duplicates\n","    input_data = [lemmatizer.lemmatize(word.lower()) for word in input_data]\n","    # create a bag of words for the input data\n","    bag_of_words = [0] * len(words)\n","    for word in input_data:\n","        for i, w in enumerate(words):\n","            if w == word:\n","                bag_of_words[i] = 1\n","    # predict the class of the input data using the trained model\n","    result = model.predict(np.array([bag_of_words]))[0]\n","    # get the index of the predicted class\n","    index = np.argmax(result)\n","    # get the tag of the predicted class\n","    tag = classes[index]\n","\n","    # if the predicted class has a confidence score lower than 0.5, return a default response\n","    if result[index] < 0.5:\n","        return \"I'm sorry, I don't understand. Can you please try again with different words?\"\n","\n","    # loop through the intents and find the one with the matching tag\n","    for intent in intents['intents']:\n","        if intent['tag'] == tag:\n","            # choose a random response from the list of responses\n","            response = np.random.choice(intent['responses'])\n","            return response"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1991,"status":"ok","timestamp":1680367472866,"user":{"displayName":"Ahmed Waleed","userId":"03707278580333724727"},"user_tz":-120},"id":"ayvixs56BNrk","outputId":"7608aaa6-f7be-4512-bca9-14fb43f566c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Press 0 if you don't want to chat with our ChatBot.\n","''You: 0\n"]}],"source":["print(\"Press 0 if you don't want to chat with our ChatBot.\")\n","# test the chatbot model\n","while True:\n","    # get user input\n","    user_input = input(\"''You: \")\n","    # Condition if the user press 0 it terminates\n","    if user_input == \"0\":\n","     break\n","    # Predict the intent of input\n","    print(predict_intent(user_input))\n","    # get chatbot response\n","    chatbot_output = chatbot_response(user_input)\n","    print(\"Chatbot:\", chatbot_output)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO0f3eGED8qXlWMahh5O3kA","mount_file_id":"1b4lNqzXZji4ouw6rzdAk2ETI7nHrjKn8","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
